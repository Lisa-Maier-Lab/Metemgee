{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute metagenome functional profile with Paladin\n",
    "Jacobo de la Cuesta-Zuluaga. June 2025.\n",
    "\n",
    "The aim of this notebook is to obtain the functional profile from metagenome samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Before we start\n",
    "This notebook assumes that the sequences already went through QC. In this case, we're using the output files from the `taxprofiler` pipeline, which performs sequence quality control and removal of host sequences. See notebook 01 for that. \n",
    "\n",
    "In addition, you need to have a `conda` environment with `paladin` installed. [See their repo here.](https://github.com/ToniWestbrook/paladin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries and set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "library(tidyverse)\n",
    "library(conflicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m\u001b[90m[conflicted]\u001b[39m Removing existing preference.\n",
      "\u001b[1m\u001b[22m\u001b[90m[conflicted]\u001b[39m Will prefer \u001b[1m\u001b[34mdplyr\u001b[39m\u001b[22m::filter over any other package.\n"
     ]
    }
   ],
   "source": [
    "# Solve conflicts\n",
    "conflicts_prefer(dplyr::filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in dir.create(paladin_dir):\n",
      "“'/mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin' already exists”\n",
      "Warning message in dir.create(out_dir):\n",
      "“'/mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin/output' already exists”\n",
      "Warning message in dir.create(sheets_dir):\n",
      "“'/mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin/sheets' already exists”\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "# Base directory\n",
    "base_dir = \"/mnt/lustre/groups/maier/maide581/projects/Metemgee\"\n",
    "\n",
    "# Data\n",
    "data_dir = file.path(base_dir, \"data\")\n",
    "\n",
    "# Sequences\n",
    "seq_dir = file.path(data_dir, \"taxprofiler/analysis_ready_fastqs\")\n",
    "\n",
    "# Out\n",
    "paladin_dir = file.path(data_dir, \"paladin\")\n",
    "dir.create(paladin_dir)\n",
    "\n",
    "# Paladin output\n",
    "out_dir = file.path(paladin_dir, \"output\")\n",
    "dir.create(out_dir)\n",
    "\n",
    "# Sheets dir\n",
    "sheets_dir = file.path(paladin_dir, \"sheets\")\n",
    "dir.create(sheets_dir)\n",
    "\n",
    "# tmp dir\n",
    "tmp_dir = tempdir()\n",
    "\n",
    "# paladin index\n",
    "paladin_index = \"/mnt/lustre/groups/maier/databases/Paladin/uhgp-90.faa\"\n",
    "\n",
    "conda_env = \"paladin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the sequences we have previously processed. These are two quality-controlled samples using the `nf-core/taxprofiler` pipeline. For instructions on how to retrieve and perform QC, see the `01_Run_QC_Taxprofiler.ipynb` notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Paladin\n",
    "\n",
    "To execute `paladin` we'll need an indexed reference. For general usage with human metagenome samples, we can use the Unified Human Gut Genome (UHGG) protein cataolg. To see how the index was created or create your own, see the notebok in the `Metemgee/helper_scripts/paladin_index` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create samples file\n",
    "Similar to the file we passed to taxprofiler, we'll need to create a file with the name of the sample and the files corresponding to forward and reverse reads.\n",
    "\n",
    "Importantly, this file needs to have a first column called `ArrayTaskID` with the number of the sample (1 for first sample, 2 for second and so on).\n",
    "\n",
    "**Note** that in this case we'll need the clean reads, not the raw reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 2 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ArrayTaskID</th><th scope=col>Sample_name</th><th scope=col>Forward</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>MI-142-H</td><td>/mnt/lustre/groups/maier/maide581/projects/Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-142-H_1.merged.fastq.gz</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>MI-237-H</td><td>/mnt/lustre/groups/maier/maide581/projects/Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-237-H_1.merged.fastq.gz</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & ArrayTaskID & Sample\\_name & Forward\\\\\n",
       "  & <int> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & MI-142-H & /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/taxprofiler/analysis\\_ready\\_fastqs/MI-142-H\\_1.merged.fastq.gz\\\\\n",
       "\t2 & 2 & MI-237-H & /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/taxprofiler/analysis\\_ready\\_fastqs/MI-237-H\\_1.merged.fastq.gz\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 × 3\n",
       "\n",
       "| <!--/--> | ArrayTaskID &lt;int&gt; | Sample_name &lt;chr&gt; | Forward &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 1 | MI-142-H | /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-142-H_1.merged.fastq.gz |\n",
       "| 2 | 2 | MI-237-H | /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-237-H_1.merged.fastq.gz |\n",
       "\n"
      ],
      "text/plain": [
       "  ArrayTaskID Sample_name\n",
       "1 1           MI-142-H   \n",
       "2 2           MI-237-H   \n",
       "  Forward                                                                                                              \n",
       "1 /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-142-H_1.merged.fastq.gz\n",
       "2 /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-237-H_1.merged.fastq.gz"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create samples file\n",
    "# List clean sequences\n",
    "clean_seq_list = list.files(seq_dir,  \n",
    "        pattern = \"1.merged.fastq.gz\",\n",
    "        full.names = TRUE)\n",
    "\n",
    "# Combine lists of files to create a data frame\n",
    "reads_df = data.frame(Forward = clean_seq_list) %>%\n",
    "    mutate(Sample_name = basename(Forward), # Sample name from the file\n",
    "        Sample_name = str_remove(Sample_name, \"_[0-9]\\\\.merged.*\"),\n",
    "        ArrayTaskID = row_number()) %>%\n",
    "    relocate(ArrayTaskID, Sample_name, Forward) # Reorder columns\n",
    "\n",
    "reads_df %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Write samples file\n",
    "paladin_samplesfile = file.path(data_dir, \"samples_file_paladin.tsv\")\n",
    "write_tsv(reads_df,\n",
    "    file = paladin_samplesfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "paladin_array_slurm_raw = str_glue(.open = \"[\", .close = \"]\",\n",
    "\"#!/bin/bash\n",
    "##############################\n",
    "#       Parameters           #\n",
    "##############################\n",
    "\n",
    "# This section will tell the cluster what are the resources your job will need.\n",
    "# Change the parameters accordingly and carefully!\n",
    "# The parameters here are a sensible start.\n",
    "\n",
    "# Name of the job\n",
    "#SBATCH --job-name=[[job_name]]\n",
    "\n",
    "# Generate an output file and give it a name\n",
    "#SBATCH --output=%x-%j.out\n",
    "\n",
    "# Number of tasks\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "# Number of cpus that this task will need\n",
    "#SBATCH --cpus-per-task=[[cpu]]\n",
    "\n",
    "# Specify the total memory required per node\n",
    "#SBATCH --mem=[[mem]]\n",
    "\n",
    "# Specify the maximum time this job can take to run before being killed (hh:mm:ss)\n",
    "#SBATCH --time=23:59:59\n",
    "\n",
    "# Specify number of array jobs\n",
    "#SBATCH --array=[[array_jobs]]%10\n",
    "\n",
    "# job information\n",
    "scontrol show job ${SLURM_JOB_ID}\n",
    "\n",
    "# per node\n",
    "# prep\n",
    "source $HOME/.bashrc\n",
    "\n",
    "# Specify the path to the config file\n",
    "config=[[samples_file]]\n",
    "\n",
    "# Extract the sample name for the current $SLURM_ARRAY_TASK_ID\n",
    "sample=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)\n",
    "\n",
    "# Extract the path to the forward read for the current $SLURM_ARRAY_TASK_ID\n",
    "forward=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $3}' $config)\n",
    "\n",
    "# Print to a file a message that includes the current $SLURM_ARRAY_TASK_ID and sample name\n",
    "echo This is array task ${SLURM_ARRAY_TASK_ID}, the sample name is ${sample} the forward read is ${forward}\n",
    "\n",
    "# do your real computation\n",
    "# Activate conda\n",
    "conda activate [[conda_env]]\n",
    "cd [[out_dir]]\n",
    "\n",
    "# Create tmp dir\n",
    "base_tmp='[[tmp_dir]]'\n",
    "tmp_dir=${base_tmp}/${sample}'_tmp'\n",
    "mkdir -p ${tmp_dir}\n",
    "\n",
    "# Execute paladin and create sorted bam file\n",
    "paladin align -t [[cpu]] [[index]] ${forward} | \\\n",
    "    samtools view -@ [[cpu]] -b - | \\\n",
    "    samtools sort -@ [[cpu]] - > ${tmp_dir}/${sample}.sorted.bam\n",
    "\n",
    "# Extract counts\n",
    "samtools index -@ [[64]] ${tmp_dir}/${sample}.sorted.bam\n",
    "samtools idxstats -@ [[cpu]] ${tmp_dir}/${sample}.sorted.bam | gzip > ${sample}.counts.gz\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#!/bin/bash\n",
      "##############################\n",
      "#       Parameters           #\n",
      "##############################\n",
      "\n",
      "# This section will tell the cluster what are the resources your job will need.\n",
      "# Change the parameters accordingly and carefully!\n",
      "# The parameters here are a sensible start.\n",
      "\n",
      "# Name of the job\n",
      "#SBATCH --job-name=paladin_array\n",
      "\n",
      "# Generate an output file and give it a name\n",
      "#SBATCH --output=%x-%j.out\n",
      "\n",
      "# Number of tasks\n",
      "#SBATCH --ntasks=1\n",
      "\n",
      "# Number of cpus that this task will need\n",
      "#SBATCH --cpus-per-task=16\n",
      "\n",
      "# Specify the total memory required per node\n",
      "#SBATCH --mem=64G\n",
      "\n",
      "# Specify the maximum time this job can take to run before being killed (hh:mm:ss)\n",
      "#SBATCH --time=23:59:59\n",
      "\n",
      "# Specify number of array jobs\n",
      "#SBATCH --array=1-2\n",
      "\n",
      "# job information\n",
      "scontrol show job ${SLURM_JOB_ID}\n",
      "\n",
      "# per node\n",
      "# prep\n",
      "source $HOME/.bashrc\n",
      "\n",
      "# Specify the path to the config file\n",
      "config=/mnt/lustre/groups/maier/maide581/projects/Metemgee/data/samples_file_paladin.tsv\n",
      "\n",
      "# Extract the sample name for the current $SLURM_ARRAY_TASK_ID\n",
      "sample=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)\n",
      "\n",
      "# Extract the path to the forward read for the current $SLURM_ARRAY_TASK_ID\n",
      "forward=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $3}' $config)\n",
      "\n",
      "# Print to a file a message that includes the current $SLURM_ARRAY_TASK_ID and sample name\n",
      "echo This is array task ${SLURM_ARRAY_TASK_ID}, the sample name is ${sample} the forward read is ${forward}\n",
      "\n",
      "# do your real computation\n",
      "# Activate conda\n",
      "conda activate paladin\n",
      "cd /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin/output\n",
      "\n",
      "# Create tmp dir\n",
      "base_tmp='/tmp/RtmpeM7kBt'\n",
      "tmp_dir=${base_tmp}/${sample}'_tmp'\n",
      "mkdir -p ${tmp_dir}\n",
      "\n",
      "# Execute paladin and create sorted bam file\n",
      "paladin align -t 16 /mnt/lustre/groups/maier/databases/Paladin/uhgp-90.faa ${forward} | \n",
      "    samtools view -@ 16 -b - | \n",
      "    samtools sort -@ 16 - > ${tmp_dir}/${sample}.sorted.bam\n",
      "\n",
      "# Extract counts\n",
      "samtools index -@ 64 ${tmp_dir}/${sample}.sorted.bam\n",
      "samtools idxstats -@ 16 ${tmp_dir}/${sample}.sorted.bam | gzip > ${sample}.counts.gz\n"
     ]
    }
   ],
   "source": [
    "paladin_array_slurm = str_glue(paladin_array_slurm_raw,\n",
    "        job_name = \"paladin_array\", \n",
    "        array_jobs = str_c(\"1-\", nrow(reads_df)), # number of array jobs should be expressed as 1-<number of samples to run>, if 10 samples, 1-10\n",
    "        samples_file = paladin_samplesfile, # Samples file we created above\n",
    "        index = paladin_index,\n",
    "        out_dir = out_dir,\n",
    "        tmp_dir = tmp_dir,\n",
    "        cpu = 16,\n",
    "        mem = \"64G\",\n",
    "        conda_env = conda_env, # Name of conda environment, defined above\n",
    "        .open = \"[\", .close = \"]\") \n",
    "\n",
    "paladin_array_slurm %>%\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Write file\n",
    "array_slurmfile = file.path(sheets_dir, \"array_slurm.sh\")\n",
    "write_lines(paladin_array_slurm, array_slurmfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'cd /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin/sheets &amp;&amp; sbatch /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin/sheets/array_slurm.sh'"
      ],
      "text/latex": [
       "'cd /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin/sheets \\&\\& sbatch /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin/sheets/array\\_slurm.sh'"
      ],
      "text/markdown": [
       "'cd /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin/sheets &amp;&amp; sbatch /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin/sheets/array_slurm.sh'"
      ],
      "text/plain": [
       "cd /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin/sheets && sbatch /mnt/lustre/groups/maier/maide581/projects/Metemgee/data/paladin/sheets/array_slurm.sh"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Command\n",
    "str_glue(\"cd {sheets_dir} && sbatch {slurmfile}\",\n",
    "         out_dir = out_dir,\n",
    "         slurmfile = array_slurmfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: Downstream steps are to be done after paladin finished executing\n",
     "output_type": "error",
     "traceback": [
      "Error: Downstream steps are to be done after paladin finished executing\nTraceback:\n",
      "1. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = invokeRestart(\"eval_error\", \n .             cnd))\n . }, \"Downstream steps are to be done after paladin finished executing\", \n .     base::quote(eval(expr, envir)))"
     ]
    }
   ],
   "source": [
    "stop(\"Downstream steps are to be done after paladin finished executing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge tables\n",
    "The output of `paladin` is a table per sample. To generate a single merged table with annotations, run the following chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Read output files and create a single table\n",
    "UGHH_table_raw = out_dir %>%\n",
    "    list.files(full.names = TRUE, pattern = \"counts.gz\") %>%\n",
    "    map_df(function(filename){\n",
    "        # Name of sample\n",
    "        sample_name = basename(filename) %>% \n",
    "            str_remove(\".counts.gz\")\n",
    "            \n",
    "        # Read tables and add sample name\n",
    "        filename %>%\n",
    "            read_tsv(col_names = c(\"Gene\", \"Length\", \"Mapped\", \"Unmapped\"), show_col_types = FALSE) %>%\n",
    "            mutate(Sample = sample_name)\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>Sample</th><th scope=col>Unmapped</th><th scope=col>Total_mapped</th><th scope=col>Unmapped_per</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>MI-142-H</td><td>1263266</td><td>20446606</td><td>5.82</td></tr>\n",
       "\t<tr><td>MI-237-H</td><td> 477818</td><td>11920522</td><td>3.85</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2 × 4\n",
       "\\begin{tabular}{llll}\n",
       " Sample & Unmapped & Total\\_mapped & Unmapped\\_per\\\\\n",
       " <chr> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t MI-142-H & 1263266 & 20446606 & 5.82\\\\\n",
       "\t MI-237-H &  477818 & 11920522 & 3.85\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2 × 4\n",
       "\n",
       "| Sample &lt;chr&gt; | Unmapped &lt;dbl&gt; | Total_mapped &lt;dbl&gt; | Unmapped_per &lt;dbl&gt; |\n",
       "|---|---|---|---|\n",
       "| MI-142-H | 1263266 | 20446606 | 5.82 |\n",
       "| MI-237-H |  477818 | 11920522 | 3.85 |\n",
       "\n"
      ],
      "text/plain": [
       "  Sample   Unmapped Total_mapped Unmapped_per\n",
       "1 MI-142-H 1263266  20446606     5.82        \n",
       "2 MI-237-H  477818  11920522     3.85        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Number of mapped reads\n",
    "Mapped_reads = UGHH_table_raw %>% \n",
    "    filter(Gene != fixed(\"*\")) %>% \n",
    "    group_by(Sample) %>% \n",
    "    summarise(Total_mapped = sum(Mapped)) %>% \n",
    "    ungroup()\n",
    "\n",
    "# Fraction of unmapped reads\n",
    "Unmapped_reads = UGHH_table_raw %>% \n",
    "    filter(Gene == fixed(\"*\")) %>% \n",
    "    select(Sample, Unmapped) %>% \n",
    "    left_join(Mapped_reads, by = join_by(\"Sample\")) %>% \n",
    "    mutate(Unmapped_per = round((Unmapped/(Unmapped + Total_mapped)*100), 2))\n",
    "\n",
    "\n",
    "Unmapped_reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Counts table\n",
    "UGHH_table_wide = UGHH_table_raw %>% \n",
    "    group_by(Sample) %>% \n",
    "    filter(Mapped > 0) %>% \n",
    "    ungroup %>% \n",
    "    pivot_wider(id_cols = Gene, \n",
    "                names_from = Sample, \n",
    "                values_from = Mapped, \n",
    "                values_fill = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mRows: \u001b[22m\u001b[34m10271996\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m21\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \"\\t\"\n",
      "\u001b[31mchr\u001b[39m (19): #query, seed_ortholog, eggNOG_OGs, max_annot_lvl, COG_category, De...\n",
      "\u001b[32mdbl\u001b[39m  (2): evalue, score\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    }
   ],
   "source": [
    "# UHGG eggNOG file\n",
    "# Only contains the genes detected in the samples\n",
    "eggNOG_annotation = \"/mnt/lustre/groups/maier/databases/UHGG/Protein_catalog/uhgp-90/uhgp-90_eggNOG.tsv\" %>% \n",
    "    read_tsv() %>% \n",
    "    rename(\"Gene\" = \"#query\")  %>% \n",
    "    filter(Gene %in% UGHH_table_wide$Gene) %>% \n",
    "    select(Gene, eggNOG_OG = eggNOG_OGs, COG_category, Description, Preferred_name, EC, KEGG_ko, KEGG_Module, KEGG_Pathway) %>% \n",
    "    mutate(eggNOG_OG = str_extract(eggNOG_OG, \".*root\"),\n",
    "           eggNOG_OG = str_remove_all(eggNOG_OG, fixed(\"@1|root\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Write tables\n",
    "# You can change the output directory or the name of the file if you wish\n",
    "# By default it is located in the paladin directory\n",
    "count_file = file.path(out_dir, \"Merged_paladin_counts.tsv.gz\")\n",
    "write_tsv(UGHH_table_wide, count_file)\n",
    "\n",
    "# Write tables\n",
    "annotation_file = file.path(out_dir, \"Merged_paladin_annotation.tsv.gz\")\n",
    "write_tsv(eggNOG_annotation, annotation_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
