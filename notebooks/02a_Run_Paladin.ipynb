{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute metagenome functional profile with Paladin\n",
    "Jacobo de la Cuesta-Zuluaga. June 2025.\n",
    "\n",
    "The aim of this notebook is to obtain the functional profile from metagenome samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Before we start\n",
    "This notebook assumes that the sequences already went through QC. In this case, we're using the output files from the `taxprofiler` pipeline, which performs sequence quality control and removal of host sequences. See notebook 01 for that. \n",
    "\n",
    "In addition, you need to have a `conda` environment with `paladin` installed. [See their repo here.](https://github.com/ToniWestbrook/paladin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries and set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching core tidyverse packages\u001b[22m ──────────────────────── tidyverse 2.0.0 ──\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdplyr    \u001b[39m 1.1.4     \u001b[32m✔\u001b[39m \u001b[34mreadr    \u001b[39m 2.1.5\n",
      "\u001b[32m✔\u001b[39m \u001b[34mforcats  \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mstringr  \u001b[39m 1.5.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2  \u001b[39m 3.5.1     \u001b[32m✔\u001b[39m \u001b[34mtibble   \u001b[39m 3.2.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mlubridate\u001b[39m 1.9.3     \u001b[32m✔\u001b[39m \u001b[34mtidyr    \u001b[39m 1.3.1\n",
      "\u001b[32m✔\u001b[39m \u001b[34mpurrr    \u001b[39m 1.0.2     \n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[36mℹ\u001b[39m Use the conflicted package (\u001b[3m\u001b[34m<http://conflicted.r-lib.org/>\u001b[39m\u001b[23m) to force all conflicts to become errors\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "library(tidyverse)\n",
    "library(conflicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[22m\u001b[90m[conflicted]\u001b[39m Will prefer \u001b[1m\u001b[34mdplyr\u001b[39m\u001b[22m::filter over any other package.\n"
     ]
    }
   ],
   "source": [
    "# Solve conflicts\n",
    "conflicts_prefer(dplyr::filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in dir.create(paladin_dir):\n",
      "“cannot create dir '/PATH/TO/YOUR/PROJECT/FOLDER/data/paladin', reason 'No such file or directory'”\n",
      "Warning message in dir.create(out_dir):\n",
      "“cannot create dir '/PATH/TO/YOUR/PROJECT/FOLDER/data/paladin/output', reason 'No such file or directory'”\n",
      "Warning message in dir.create(sheets_dir):\n",
      "“cannot create dir '/PATH/TO/YOUR/PROJECT/FOLDER/data/paladin/sheets', reason 'No such file or directory'”\n",
      "Warning message in dir.create(tmp_dir):\n",
      "“'/tmp/RtmpZLaKq0' already exists”\n",
      "Warning message in dir.create(bin_dir):\n",
      "“cannot create dir '/PATH/TO/YOUR/PROJECT/FOLDER/bin', reason 'No such file or directory'”\n"
     ]
    }
   ],
   "source": [
    "# Directories\n",
    "# Base directory\n",
    "base_dir = \"/PATH/TO/YOUR/PROJECT/FOLDER\"\n",
    "\n",
    "# Data\n",
    "data_dir = file.path(base_dir, \"data\")\n",
    "\n",
    "# Out\n",
    "paladin_dir = file.path(data_dir, \"paladin\")\n",
    "dir.create(paladin_dir)\n",
    "\n",
    "# Paladin output\n",
    "out_dir = file.path(paladin_dir, \"output\")\n",
    "dir.create(out_dir)\n",
    "\n",
    "# Sheets dir\n",
    "sheets_dir = file.path(paladin_dir, \"sheets\")\n",
    "dir.create(sheets_dir)\n",
    "\n",
    "# tmp dir\n",
    "tmp_dir = tempdir()\n",
    "dir.create(tmp_dir)\n",
    "\n",
    "# Software\n",
    "bin_dir = file.path(base_dir, \"bin\")\n",
    "dir.create(bin_dir)\n",
    "\n",
    "conda_env = \"paladin\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the sequences we have previously processed. These are two quality-controlled samples using the `nf-core/taxprofiler` pipeline. For instructions on how to retrieve and perform QC, see the `01_Run_QC_Taxprofiler.ipynb` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'MI-142-H_run_1.merged.fastq.gz'</li><li>'MI-142-H_run_2.merged.fastq.gz'</li><li>'MI-142-H.merged.fastq.gz'</li><li>'MI-237-H_run_1.merged.fastq.gz'</li><li>'MI-237-H_run_2.merged.fastq.gz'</li><li>'MI-237-H_run_3.merged.fastq.gz'</li><li>'MI-237-H_run_4.merged.fastq.gz'</li><li>'MI-237-H.merged.fastq.gz'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'MI-142-H\\_run\\_1.merged.fastq.gz'\n",
       "\\item 'MI-142-H\\_run\\_2.merged.fastq.gz'\n",
       "\\item 'MI-142-H.merged.fastq.gz'\n",
       "\\item 'MI-237-H\\_run\\_1.merged.fastq.gz'\n",
       "\\item 'MI-237-H\\_run\\_2.merged.fastq.gz'\n",
       "\\item 'MI-237-H\\_run\\_3.merged.fastq.gz'\n",
       "\\item 'MI-237-H\\_run\\_4.merged.fastq.gz'\n",
       "\\item 'MI-237-H.merged.fastq.gz'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'MI-142-H_run_1.merged.fastq.gz'\n",
       "2. 'MI-142-H_run_2.merged.fastq.gz'\n",
       "3. 'MI-142-H.merged.fastq.gz'\n",
       "4. 'MI-237-H_run_1.merged.fastq.gz'\n",
       "5. 'MI-237-H_run_2.merged.fastq.gz'\n",
       "6. 'MI-237-H_run_3.merged.fastq.gz'\n",
       "7. 'MI-237-H_run_4.merged.fastq.gz'\n",
       "8. 'MI-237-H.merged.fastq.gz'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"MI-142-H_run_1.merged.fastq.gz\" \"MI-142-H_run_2.merged.fastq.gz\"\n",
       "[3] \"MI-142-H.merged.fastq.gz\"       \"MI-237-H_run_1.merged.fastq.gz\"\n",
       "[5] \"MI-237-H_run_2.merged.fastq.gz\" \"MI-237-H_run_3.merged.fastq.gz\"\n",
       "[7] \"MI-237-H_run_4.merged.fastq.gz\" \"MI-237-H.merged.fastq.gz\"      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sequences\n",
    "seq_dir = \"/mnt/lustre/groups/maier/maide581/projects/Small_projects/diamond_Metemgee/data/taxprofiler/analysis_ready_fastqs\"\n",
    "list.files(seq_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Paladin\n",
    "\n",
    "To execute `paladin` we'll need an indexed reference. For general usage with human metagenome samples, we can use the Unified Human Gut Genome (UHGG) protein cataolg. To see how the index was created or create your own, see the notebok in the `Metemgee/helper_scripts/paladin_index` folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create samples file\n",
    "Similar to the file we passed to taxprofiler, we'll need to create a file with the name of the sample and the files corresponding to forward and reverse reads.\n",
    "\n",
    "Importantly, this file needs to have a first column called `ArrayTaskID` with the number of the sample (1 for first sample, 2 for second and so on).\n",
    "\n",
    "**Note** that in this case we'll need the clean reads, not the raw reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 2 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>ArrayTaskID</th><th scope=col>Sample_name</th><th scope=col>Forward</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1</td><td>MI-142-H_run</td><td>/mnt/lustre/groups/maier/maide581/projects/Small_projects/diamond_Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-142-H_run_1.merged.fastq.gz</td></tr>\n",
       "\t<tr><th scope=row>2</th><td>2</td><td>MI-237-H_run</td><td>/mnt/lustre/groups/maier/maide581/projects/Small_projects/diamond_Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-237-H_run_1.merged.fastq.gz</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 2 × 3\n",
       "\\begin{tabular}{r|lll}\n",
       "  & ArrayTaskID & Sample\\_name & Forward\\\\\n",
       "  & <int> & <chr> & <chr>\\\\\n",
       "\\hline\n",
       "\t1 & 1 & MI-142-H\\_run & /mnt/lustre/groups/maier/maide581/projects/Small\\_projects/diamond\\_Metemgee/data/taxprofiler/analysis\\_ready\\_fastqs/MI-142-H\\_run\\_1.merged.fastq.gz\\\\\n",
       "\t2 & 2 & MI-237-H\\_run & /mnt/lustre/groups/maier/maide581/projects/Small\\_projects/diamond\\_Metemgee/data/taxprofiler/analysis\\_ready\\_fastqs/MI-237-H\\_run\\_1.merged.fastq.gz\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 2 × 3\n",
       "\n",
       "| <!--/--> | ArrayTaskID &lt;int&gt; | Sample_name &lt;chr&gt; | Forward &lt;chr&gt; |\n",
       "|---|---|---|---|\n",
       "| 1 | 1 | MI-142-H_run | /mnt/lustre/groups/maier/maide581/projects/Small_projects/diamond_Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-142-H_run_1.merged.fastq.gz |\n",
       "| 2 | 2 | MI-237-H_run | /mnt/lustre/groups/maier/maide581/projects/Small_projects/diamond_Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-237-H_run_1.merged.fastq.gz |\n",
       "\n"
      ],
      "text/plain": [
       "  ArrayTaskID Sample_name \n",
       "1 1           MI-142-H_run\n",
       "2 2           MI-237-H_run\n",
       "  Forward                                                                                                                                         \n",
       "1 /mnt/lustre/groups/maier/maide581/projects/Small_projects/diamond_Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-142-H_run_1.merged.fastq.gz\n",
       "2 /mnt/lustre/groups/maier/maide581/projects/Small_projects/diamond_Metemgee/data/taxprofiler/analysis_ready_fastqs/MI-237-H_run_1.merged.fastq.gz"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create samples file\n",
    "# List clean sequences\n",
    "clean_seq_list = list.files(seq_dir,  \n",
    "        pattern = \"1.merged.fastq.gz\",\n",
    "        full.names = TRUE)\n",
    "\n",
    "# Combine lists of files to create a data frame\n",
    "reads_df = data.frame(Forward = clean_seq_list) %>%\n",
    "    mutate(Sample_name = basename(Forward), # Sample name from the file\n",
    "        Sample_name = str_remove(Sample_name, \"_[0-9]\\\\.merged.*\"),\n",
    "        ArrayTaskID = row_number()) %>%\n",
    "    relocate(ArrayTaskID, Sample_name, Forward) # Reorder columns\n",
    "\n",
    "reads_df %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: Cannot open file for writing:\n* '/PATH/TO/YOUR/PROJECT/FOLDER/data/samples_file_paladin.tsv'\n",
     "output_type": "error",
     "traceback": [
      "Error: Cannot open file for writing:\n* '/PATH/TO/YOUR/PROJECT/FOLDER/data/samples_file_paladin.tsv'\nTraceback:\n",
      "1. write_delim(x, file, delim = \"\\t\", na = na, append = append, \n .     col_names = col_names, quote = quote, escape = escape, eol = eol, \n .     num_threads = num_threads, progress = progress)",
      "2. vroom::vroom_write(x, file, delim = delim, col_names = col_names, \n .     append = append, na = na, eol = eol, quote = quote, escape = escape, \n .     num_threads = num_threads, progress = progress)",
      "3. vroom_write_(x, file, delim, eol, na_str = na, col_names = col_names, \n .     append = append, options = opts, num_threads = num_threads, \n .     progress = progress, buf_lines = buf_lines)",
      "4. .handleSimpleError(function (cnd) \n . {\n .     watcher$capture_plot_and_output()\n .     cnd <- sanitize_call(cnd)\n .     watcher$push(cnd)\n .     switch(on_error, continue = invokeRestart(\"eval_continue\"), \n .         stop = invokeRestart(\"eval_stop\"), error = invokeRestart(\"eval_error\", \n .             cnd))\n . }, \"Cannot open file for writing:\\n* '/PATH/TO/YOUR/PROJECT/FOLDER/data/samples_file_paladin.tsv'\", \n .     base::quote(NULL))"
     ]
    }
   ],
   "source": [
    "# Write samples file\n",
    "paladin_samplesfile = file.path(data_dir, \"samples_file_paladin.tsv\")\n",
    "write_tsv(reads_df,\n",
    "    file = paladin_samplesfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "paladin_array_slurm_raw = str_glue(.open = \"[\", .close = \"]\",\n",
    "\"#!/bin/bash\n",
    "##############################\n",
    "#       Parameters           #\n",
    "##############################\n",
    "\n",
    "# This section will tell the cluster what are the resources your job will need.\n",
    "# Change the parameters accordingly and carefully!\n",
    "# The parameters here are a sensible start.\n",
    "\n",
    "# Name of the job\n",
    "#SBATCH --job-name=[[job_name]]\n",
    "\n",
    "# Generate an output file and give it a name\n",
    "#SBATCH --output=%x-%j.out\n",
    "\n",
    "# Number of tasks\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "# Number of cpus that this task will need\n",
    "#SBATCH --cpus-per-task=[[cpu]]\n",
    "\n",
    "# Specify the total memory required per node\n",
    "#SBATCH --mem=[[mem]]\n",
    "\n",
    "# Specify the maximum time this job can take to run before being killed (hh:mm:ss)\n",
    "#SBATCH --time=23:59:59\n",
    "\n",
    "# Specify number of array jobs\n",
    "#SBATCH --array=[[array_jobs]]\n",
    "\n",
    "# job information\n",
    "scontrol show job ${SLURM_JOB_ID}\n",
    "\n",
    "# per node\n",
    "# prep\n",
    "source $HOME/.bashrc\n",
    "\n",
    "# Specify the path to the config file\n",
    "config=[[samples_file]]\n",
    "\n",
    "# Extract the sample name for the current $SLURM_ARRAY_TASK_ID\n",
    "sample=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)\n",
    "\n",
    "# Extract the path to the forward read for the current $SLURM_ARRAY_TASK_ID\n",
    "forward=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $3}' $config)\n",
    "\n",
    "# Print to a file a message that includes the current $SLURM_ARRAY_TASK_ID and sample name\n",
    "echo This is array task ${SLURM_ARRAY_TASK_ID}, the sample name is ${sample} the forward read is ${forward}\n",
    "\n",
    "# do your real computation\n",
    "# Activate conda\n",
    "conda activate [[conda_env]]\n",
    "cd [[out_dir]]\n",
    "\n",
    "# Create tmp dir\n",
    "base_tmp='[[tmp_dir]]'\n",
    "tmp_dir=${base_tmp}/${sample}'_tmp'\n",
    "mkdir -p ${tmp_dir}\n",
    "\n",
    "# Execute paladin and create sorted bam file\n",
    "paladin align -t [[cpu]] [[index_dir]] ${forward} | \\\n",
    "    samtools view -@ [[cpu]] -b - | \\\n",
    "    samtools sort -@ [[cpu]] - > ${tmp_dir}/${sample}.sorted.bam\n",
    "\n",
    "# Extract counts\n",
    "samtools index -@ [[64]] ${tmp_dir}/${sample}.sorted.bam\n",
    "samtools idxstats -@ [[cpu]] ${tmp_dir}/${sample}.sorted.bam > ${sample}.counts\n",
    "\n",
    "rm -rf ${tmp_dir}\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "paladin_array_slurm = str_glue(paladin_array_slurm_raw,\n",
    "        job_name = \"paladin_array\", \n",
    "        array_jobs = str_c(\"1-\", nrow(reads_df)), # number of array jobs should be expressed as 1-<number of samples to run>, if 10 samples, 1-10\n",
    "        samples_file = paladin_samplesfile, # Samples file we created above\n",
    "        index_dir = Large_unannot,\n",
    "        out_dir = out_dir,\n",
    "        tmp_dir = tmp_dir,\n",
    "        cpu = 16,\n",
    "        mem = \"64G\",\n",
    "        conda_env = conda_env, # Name of conda environment, defined above\n",
    "        .open = \"[\", .close = \"]\") \n",
    "\n",
    "paladin_array_slurm %>%\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Write file\n",
    "array_slurmfile = file.path(bin_dir, \"array_slurm.sh\")\n",
    "write_lines(paladin_array_slurm, array_slurmfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
