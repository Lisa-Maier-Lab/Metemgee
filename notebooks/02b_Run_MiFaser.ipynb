{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute metagenome functional profile with mifaser\n",
    "Jacobo de la Cuesta-Zuluaga. August 2024.\n",
    "\n",
    "The aim of this notebook is to obtain the functional profile from metagenome samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start\n",
    "This notebook assumes that the sequences already went through QC. In this case, we're using the output files from the `taxprofiler` pipeline, which performs sequence quality control and removal of host sequences. See notebook 01 for that. \n",
    "\n",
    "In addition, you need to have a `conda` environment with `python v.3.8` to run `mifaser`, the functional profiler. [See their repo here.](https://bitbucket.org/bromberglab/mifaser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries and set paths\n",
    "\n",
    "First, we'll set up the libraries and the work directory where we'll save our files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "library(tidyverse)\n",
    "library(conflicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Solve conflicts\n",
    "conflicts_prefer(dplyr::filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following chunk will define the directories where the data is stored and where the output will be saved. The present example assumes everything will be contained in the same directory: `base_dir`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "# Base directory\n",
    "base_dir = \"/PATH/TO/YOUR/PROJECT/FOLDER\"\n",
    "\n",
    "# Data\n",
    "data_dir = file.path(base_dir, \"data\")\n",
    "dir.create(data_dir)\n",
    "\n",
    "# Sequences\n",
    "seq_dir = file.path(data_dir, \"taxprofiler/analysis_ready_fastqs\")\n",
    "\n",
    "# Out\n",
    "mifaser_dir = file.path(data_dir, \"mifaser\")\n",
    "dir.create(mifaser_dir)\n",
    "\n",
    "out_dir = file.path(mifaser_dir, \"output\")\n",
    "dir.create(out_dir)\n",
    "\n",
    "# sheets dir\n",
    "sheets_dir = file.path(mifaser_dir, \"sheets\")\n",
    "dir.create(sheets_dir)\n",
    "\n",
    "# Software\n",
    "bin_dir = file.path(base_dir, \"bin\")\n",
    "dir.create(bin_dir)\n",
    "conda_env = \"mifaser\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Download `mifaser`\n",
    "\n",
    "Next, we'll download the repo of the functional profiler. I have found this is the easiest way, since it comes with all the software and databases needed.\n",
    "\n",
    "You can paste the generated command in the terminal to download the repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Download mifaser repo\n",
    "# Directory\n",
    "mifaser_dir = file.path(bin_dir, \"mifaser/\")\n",
    "\n",
    "# Command\n",
    "git_cmd = str_glue(\"git clone https://bitbucket.org/bromberglab/mifaser.git {mifaser_dir}\",\n",
    "    mifaser_dir = mifaser_dir)\n",
    "\n",
    "git_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create samples file\n",
    "Similar to the file we passed to taxprofiler, we'll need to create a file with the name of the sample and the files corresponding to forward and reverse reads.\n",
    "\n",
    "Importantly, this file needs to have a first column called `ArrayTaskID` with the number of the sample (1 for first sample, 2 for second and so on).\n",
    "\n",
    "**Note** that in this case we'll need the clean reads, not the raw reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# List raw sequences\n",
    "clean_seq_list = list.files(seq_dir,  \n",
    "        pattern = \"merged.fastq.gz\",\n",
    "        full.names = TRUE)\n",
    "# F\n",
    "forward_reads = clean_seq_list %>%\n",
    "    str_subset(\"_1\")\n",
    "#R\n",
    "reverse_reads = clean_seq_list %>%\n",
    "    str_subset(\"_2\")\n",
    "\n",
    "clean_seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine lists of files to create a data frame\n",
    "reads_tax_df = data.frame(Forward = forward_reads, # Full path of forward reads\n",
    "        Reverse = reverse_reads) %>% # Full path of reverse reads\n",
    "    mutate(Sample_name = basename(Forward), # Sample name from the file\n",
    "        Sample_name = str_remove(Sample_name, \"_[0-9]\\\\.merged.*\"),\n",
    "        ArrayTaskID = row_number()) %>%\n",
    "    relocate(ArrayTaskID, Sample_name, Forward, Reverse) # Reorder columns\n",
    "\n",
    "reads_tax_df %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Write samples file\n",
    "mifaser_samplesfile = file.path(sheets_dir, \"samples_file_mifaser.tsv\")\n",
    "write_tsv(reads_tax_df,\n",
    "    file = mifaser_samplesfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create slurm script\n",
    "\n",
    "To make use of the HPC, we need to create a bash script to submit the jobs using slurm. The following chunks will create and fill the scipt based on the template, you don't need to modify anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mifaser_slurm_raw = str_glue(.open = \"[\", .close = \"]\",\n",
    "\"#!/bin/bash\n",
    "##############################\n",
    "#       Parameters           #\n",
    "##############################\n",
    "\n",
    "# This section will tell the cluster what are the resources your job will need.\n",
    "# Change the parameters accordingly and carefully!\n",
    "# The parameters here are a sensible start.\n",
    "\n",
    "# Name of the job\n",
    "#SBATCH --job-name=[[job_name]]\n",
    "\n",
    "# Generate an output file and give it a name\n",
    "#SBATCH --output=%x-%j.out\n",
    "\n",
    "# Number of tasks\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "# Number of cpus that this task will need\n",
    "#SBATCH --cpus-per-task=16\n",
    "\n",
    "# Specify the total memory required per node\n",
    "#SBATCH --mem=64G\n",
    "\n",
    "# Specify the maximum time this job can take to run before being killed (hh:mm:ss)\n",
    "#SBATCH --time=23:59:59\n",
    "\n",
    "# Specify number of array jobs\n",
    "#SBATCH --array=[[array_jobs]]\n",
    "\n",
    "# job information\n",
    "scontrol show job ${SLURM_JOB_ID}\n",
    "\n",
    "# per node\n",
    "# prep\n",
    "CONDA_PATH='[[conda_install]]'\n",
    "echo ${CONDA_PATH}\n",
    "source ${CONDA_PATH}/etc/profile.d/conda.sh\n",
    "\n",
    "# Specify the path to the config file\n",
    "config=[[samples_file]]\n",
    "\n",
    "# Extract the sample name for the current $SLURM_ARRAY_TASK_ID\n",
    "sample=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)\n",
    "\n",
    "# Extract the path to the forward read for the current $SLURM_ARRAY_TASK_ID\n",
    "forward=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $3}' $config)\n",
    "\n",
    "# Extract the path to the reverse read for the current $SLURM_ARRAY_TASK_ID\n",
    "reverse=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $4}' $config)\n",
    "\n",
    "# Print to a file a message that includes the current $SLURM_ARRAY_TASK_ID and sample name\n",
    "echo This is array task ${SLURM_ARRAY_TASK_ID}, the sample name is ${sample} the forward read is ${forward} and the reverse is ${reverse}\n",
    "\n",
    "# do your real computation\n",
    "conda activate [[conda_env]]\n",
    "cd [[mifaser_repo]]\n",
    "python -m mifaser --lanes ${forward} ${reverse} -o [[out_dir]]/${sample}_out -d GS-21-all -c 16\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mifaser_slurm = str_glue(mifaser_slurm_raw,\n",
    "        job_name = \"mifaser_run\", \n",
    "        array_jobs = str_c(\"1-\", nrow(reads_tax_df)), # number of array jobs should be expressed as 1-<number of samples to run>, if 10 samples, 1-10\n",
    "        conda_install = \"/mnt/lustre/groups/maier/maide581/bin/miniconda3\", # Path to your conda installation\n",
    "        samples_file = mifaser_samplesfile, # Samples file we created above\n",
    "        mifaser_repo = mifaser_dir, # Path to the mifaser git repo\n",
    "        out_dir = out_dir,\n",
    "        conda_env = conda_env, # Name of conda environment ro tun mifaser, defined above\n",
    "        .open = \"[\", .close = \"]\") \n",
    "\n",
    "mifaser_slurm %>%\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Write file\n",
    "mifaser_slurmfile = file.path(base_dir, \"bin/mifaser_slurm.sh\")\n",
    "write_lines(mifaser_slurm, mifaser_slurmfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, you can execute `mifaser` using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Run\n",
    "str_c(\"sbatch\", mifaser_slurmfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge tables\n",
    "The output of `mifaser` is a table per sample. To generate a single merged table with annotations, run the following chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Download EC annotation file\n",
    "# Retrieved from HUMANn3 repo\n",
    "EC_table = \"https://github.com/biobakery/humann/raw/a9f181f32b3c66b66b73cabc611ff3ac55d87033/humann/data/utility_DEMO/map_level4ec_name.txt.gz\" %>%\n",
    "    read_tsv(col_names = c(\"EC_Number\", \"Annot\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Read output files and create a single table\n",
    "EC_table_long = out_dir %>%\n",
    "    list.files(full.names = TRUE, recursive = TRUE,pattern = \"analysis\") %>%\n",
    "    map_df(function(filename){\n",
    "        # Name of sample\n",
    "        sample_name = dirname(filename) %>%\n",
    "            str_remove(out_dir) %>%\n",
    "            str_remove(\"/\") %>%\n",
    "            str_remove(\"_out\")\n",
    "            \n",
    "        # Read tables and add sample name\n",
    "        filename %>%\n",
    "            read_tsv(skip = 1,col_names = c(\"EC_Number\", \"Count\")) %>%\n",
    "            mutate(Sample = sample_name)\n",
    "            }) %>%\n",
    "    left_join(EC_table) %>%\n",
    "    select(Sample, EC_Number, Annot, Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create wide table\n",
    "EC_table = EC_table_long %>%\n",
    "    pivot_wider(id_cols = c(EC_Number, Annot),\n",
    "    names_from = Sample,   \n",
    "    values_from = Count, \n",
    "    values_fill = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Write table\n",
    "# You can change the output directory or the name of the file if you wish\n",
    "# By default it is located in the mifaser directory\n",
    "out_file = file.path(out_dir, \"Merged_mifaser_out.tsv\")\n",
    "write_tsv(EC_table, out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
