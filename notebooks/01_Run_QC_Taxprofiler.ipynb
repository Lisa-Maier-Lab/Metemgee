{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute metagenome taxonomic profile\n",
    "Jacobo de la Cuesta-Zuluaga. July 2024.\n",
    "\n",
    "The aim of this notebook is to perform quality control of raw metagenome reads and run taxprofiler pipeline\n",
    "\n",
    "\n",
    "Note: the human (and other eukaryote) genomes was obtained from https://doi.org/10.5281/zenodo.4629921.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The execution of the pipeline requires `conda` to be installed and an environment with `nextflow` available. You can find instructions about how to install conda [here](https://conda.io/projects/conda/en/latest/user-guide/install/index.html).\n",
    "\n",
    "In addition, we'll be using the `nf-core` pipeline `taxprofiler`. You can read more about `nf-core` [here](https://nf-co.re/) was well as exploring the [pipeline's documentation](https://nf-co.re/taxprofiler/1.1.8/).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Be sure to add the following to your `~/.bashrc` file. With that, we're specifying a centralized folder where the `nf-core` pipelines will be downloaded. Make sure to modify the path as required\n",
    "```\n",
    "export NXF_SINGULARITY_CACHEDIR=\"/mnt/lustre/groups/maier/YOUR_M3HPC_USERNAME/bin/nf-core\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries and set paths\n",
    "\n",
    "First, we'll set up the libraries and the work directory where we'll save our files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "library(tidyverse)\n",
    "library(conflicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Solve conflicts\n",
    "conflicts_prefer(dplyr::filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "# Base directory\n",
    "base_dir = \"/PATH/TO/YOUR/PROJECT/FOLDER\"\n",
    "\n",
    "# Data\n",
    "data_dir = file.path(base_dir, \"data\")\n",
    "dir.create(data_dir)\n",
    "\n",
    "# Sequences\n",
    "seq_dir = file.path(data_dir, \"raw_sequences\")\n",
    "dir.create(seq_dir)\n",
    "\n",
    "# Out\n",
    "out_dir = file.path(data_dir, \"taxprofiler\")\n",
    "dir.create(out_dir)\n",
    "\n",
    "# sheets dir\n",
    "sheets_dir = file.path(data_dir, \"sheets\")\n",
    "dir.create(sheets_dir)\n",
    "\n",
    "# Software\n",
    "conda_env = \"nextflow\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download test files\n",
    "\n",
    "For the present example, we'll use publicly available metagenome files. They correspond to multiple sequencing runs of two samples, this means that the same sample was sequenced multiple times to achieve the desired sequencing depth. We'll use these samples to illustrate how to merge multiple sequencing runs to obtain the metagenome profile of a single sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# URL of the files from the ENA\n",
    "example_fastqs = c(\"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880517/MI-142-H.R1.RUN0129.L7.fastq.gz\", \n",
    "    \"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880518/MI-142-H.R1.RUN0118.L4.fastq.gz\",  \n",
    "    \"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880517/MI-142-H.R2.RUN0129.L7.fastq.gz\", \n",
    "    \"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880518/MI-142-H.R2.RUN0118.L4.fastq.gz\",\n",
    "    \"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880579/MI-237-H.R2.RUN0129.L7.fastq.gz\",\n",
    "    \"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880581/MI-237-H.R1.RUN0118.L2.fastq.gz\",\n",
    "    \"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880577/MI-237-H.R1.RUN0173.L6.fastq.gz\",\n",
    "    \"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880582/MI-237-H.R1.RUN0102.L5.fastq.gz\",\n",
    "    \"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880579/MI-237-H.R1.RUN0129.L7.fastq.gz\",\n",
    "    \"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880581/MI-237-H.R2.RUN0118.L2.fastq.gz\",\n",
    "    \"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880577/MI-237-H.R2.RUN0173.L6.fastq.gz\",\n",
    "    \"ftp://ftp.sra.ebi.ac.uk/vol1/run/ERR108/ERR10880582/MI-237-H.R2.RUN0102.L5.fastq.gz\")\n",
    "\n",
    "example_fastqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Download files\n",
    "# This will take a few minutes\n",
    "#map(example_fastqs, function(url){\n",
    "#    download.file(url = url, destfile = file.path(seq_dir, basename(url)), method = \"wget\")\n",
    "#})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Samples file\n",
    "\n",
    "We need to tell the pipeline which files correspond to which samples, to which sequencing run they correspond and where in our machine are stored those files. We do this by creating table where we specify the sample name and the location of the forward and reverse `fastq` files. \n",
    "\n",
    "In addition, we need to tell the pipeline which sequencing technology we used. In this case, we used an _Illumina_ machine, meaning that we got short reads. The specific software used by the pipeline will change according to this.\n",
    "\n",
    "**Note** that you can create this table by hand using excel or a text editor program, and exporting it as a `csv` file. In this example we're doing this programatically to use the information of the sample name from the full path of the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# List raw sequences\n",
    "raw_seq_list = list.files(seq_dir,  \n",
    "        pattern = \"fastq.gz\",\n",
    "        full.names = TRUE)\n",
    "# F\n",
    "forward_reads = raw_seq_list %>%\n",
    "    str_subset(\"R1\")\n",
    "#R\n",
    "reverse_reads = raw_seq_list %>%\n",
    "    str_subset(\"R2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine\n",
    "reads_tax_df = data.frame(fastq_1 = forward_reads, # Full path of forward reads\n",
    "        fastq_2 = reverse_reads, # Full path of reverse reads\n",
    "        instrument_platform = \"ILLUMINA\", # Sequencing platform \n",
    "        fasta = \"\") %>% # Empty field since we don't have fasta files\n",
    "    mutate(sample = basename(fastq_1), # Sample name from the file\n",
    "        sample = str_remove(sample, \"\\\\.R1.*\")) %>%\n",
    "    group_by(sample) %>%\n",
    "    mutate(run_accession = str_c(\"run_\", row_number())) %>% # If more than one run, specify which run it was\n",
    "    relocate(sample, instrument_platform, run_accession) # Reorder columns\n",
    "\n",
    "reads_tax_df %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Write samples file\n",
    "samples_sheet_tax = file.path(sheets_dir, \"samples_file_taxprofiler.csv\")\n",
    "write_csv(reads_tax_df,file = samples_sheet_tax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline requires a file with the location of the databases for the software to be used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create dbs file\n",
    "dbs_df = data.frame(tool = c(\"kraken2\",\"bracken\", \"metaphlan\", \"motus\"),\n",
    "    db_name = c(\"k2_standard_16gb\", \"B_standard_16gb\", \"metaphlan\", \"db_mOTU\"),\n",
    "    db_params = c(\"\", \";-r 150\", \"\", \"\"),\n",
    "    db_path = c(\"/mnt/lustre/groups/maier/databases/Kraken_Bracken/k2_standard_16gb/k2_standard_16gb_20240605.tar.gz\",\n",
    "                \"/mnt/lustre/groups/maier/databases/Kraken_Bracken/k2_standard_16gb/k2_standard_16gb_20240605.tar.gz\",\n",
    "                \"/mnt/lustre/groups/maier/databases/Metaphlan\",\n",
    "                \"/mnt/lustre/groups/maier/databases/mOTUs/db_mOTU\")) \n",
    "\n",
    "dbs_df\n",
    "\n",
    "# Write file\n",
    "dbs_file = file.path(sheets_dir, \"database_file.csv\")\n",
    "dbs_df %>%\n",
    "    write_csv(dbs_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Taxdump folder\n",
    "taxdump_dir = \"/mnt/lustre/groups/maier/databases/Taxdump\"\n",
    "\n",
    "# Host genomes\n",
    "host_genome = \"/mnt/lustre/groups/maier/databases/Host_genomes/hg19_main_mask_ribo_animal_allplant_allfungus.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create command\n",
    "# Base command\n",
    "# To run metaphlan add  --run_metaphlan\n",
    "taxprofiler_cmd = str_glue(\n",
    "  \"conda activate {{conda_env}} && \\\\\n",
    "  cd {{out_dir}} && \\\\\n",
    "  nextflow run nf-core/taxprofiler -r 1.1.8 \\\\\n",
    "  --input {{samples_sheet}} \\\\\n",
    "  --databases {{databases_sheet}} \\\\\n",
    "  --outdir {{out_dir}} \\\\\n",
    "  -profile m3c \\\\\n",
    "  --perform_shortread_qc \\\\\n",
    "  --perform_shortread_hostremoval \\\\\n",
    "  --perform_runmerging \\\\\n",
    "  --shortread_qc_dedup \\\\\n",
    "  --save_analysis_ready_fastqs \\\\\n",
    "  --hostremoval_reference {{host_genome}} \\\\\n",
    "  --run_profile_standardisation \\\\\n",
    "  --taxpasta_taxonomy_dir {{tax_dir}} \\\\\n",
    "  --taxpasta_add_name \\\\\n",
    "  --taxpasta_add_rank \\\\\n",
    "  --taxpasta_add_lineage \\\\\n",
    "  --taxpasta_add_ranklineage \\\\\n",
    "  --run_kraken2 \\\\\n",
    "  --run_bracken \\\\\n",
    "  --run_motus\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Fill command\n",
    "Clean_tax_cmd = str_glue(taxprofiler_cmd,\n",
    "                         conda_env = conda_env,\n",
    "                         samples_sheet = samples_sheet_tax,\n",
    "                         databases_sheet = dbs_file,\n",
    "                         tax_dir = taxdump_dir,\n",
    "                         host_genome = host_genome,\n",
    "                         out_dir = out_dir)\n",
    "\n",
    "Clean_tax_cmd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
