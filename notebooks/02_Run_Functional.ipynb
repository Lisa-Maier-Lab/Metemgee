{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute metagenome functional profile\n",
    "Jacobo de la Cuesta-Zuluaga. July 2024.\n",
    "\n",
    "The aim of this notebook is to obtain the functional profile from metagenome samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we start\n",
    "This notebook assumes that the sequences already went through QC. In this case, we're using the output files from the `taxprofiler` pipeline, which performs sequence quality control and removal of host sequences. See notebook 01 for that. \n",
    "\n",
    "In addition, you need to have a `conda` environment with `python v.3.8` to run `mifaser`, the functional profiler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries and set paths\n",
    "\n",
    "First, we'll set up the libraries and the work directory where we'll save our files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries\n",
    "library(tidyverse)\n",
    "library(conflicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Solve conflicts\n",
    "conflicts_prefer(dplyr::filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Directories\n",
    "# Base directory\n",
    "base_dir = \"/PATH/TO/YOUR/PROJECT/FOLDER\"\n",
    "\n",
    "# Data\n",
    "data_dir = file.path(base_dir, \"data\")\n",
    "dir.create(data_dir)\n",
    "\n",
    "# Sequences\n",
    "seq_dir = file.path(data_dir, \"taxprofiler/analysis_ready_fastqs\")\n",
    "\n",
    "# Out\n",
    "out_dir = file.path(data_dir, \"mifaser\")\n",
    "dir.create(out_dir)\n",
    "\n",
    "# sheets dir\n",
    "sheets_dir = file.path(data_dir, \"sheets\")\n",
    "dir.create(sheets_dir)\n",
    "\n",
    "# Software\n",
    "bin_dir = file.path(base_dir, \"bin\")\n",
    "dir.create(bin_dir)\n",
    "conda_env = \"mifaser\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "## Download `mifaser`\n",
    "\n",
    "Next, we'll download the repo of the functional profiler. I have found this is the easiest way, since it comes with all the software and databases needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Download mifaser repo\n",
    "# Directory\n",
    "mifaser_dir = file.path(bin_dir, \"mifaser/\")\n",
    "\n",
    "# Command\n",
    "git_cmd = str_glue(\"git clone https://bitbucket.org/bromberglab/mifaser.git {mifaser_dir}\",\n",
    "    mifaser_dir = mifaser_dir)\n",
    "\n",
    "git_cmd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create samples file\n",
    "Similar to the file we passed to taxprofiler, we'll need to create a file with the name of the sample and the files corresponding to forward and reverse reads.\n",
    "\n",
    "Importantly, this file needs to have a first column called `ArrayTaskID` with the number of the sample (1 for first sample, 2 for second and so on).\n",
    "\n",
    "**Note** that in this case we'll need the clean reads, not the raw reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "#ArrayTaskID     Sample_name     Forward Reverse\n",
    "# List raw sequences\n",
    "clean_seq_list = list.files(seq_dir,  \n",
    "        pattern = \"merged.fastq.gz\",\n",
    "        full.names = TRUE)\n",
    "# F\n",
    "forward_reads = clean_seq_list %>%\n",
    "    str_subset(\"_1\")\n",
    "#R\n",
    "reverse_reads = clean_seq_list %>%\n",
    "    str_subset(\"_2\")\n",
    "\n",
    "    clean_seq_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "data.frame(forward = forward_reads, # Full path of forward reads\n",
    "        reverse = reverse_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine\n",
    "reads_tax_df = data.frame(Forward = forward_reads, # Full path of forward reads\n",
    "        Reverse = reverse_reads) %>% # Full path of reverse reads\n",
    "    mutate(Sample_name = basename(Forward), # Sample name from the file\n",
    "        Sample_name = str_remove(Sample_name, \"_[0-9]\\\\.merged.*\"),\n",
    "        ArrayTaskID = row_number()) %>%\n",
    "    relocate(ArrayTaskID, Sample_name, Forward, Reverse) # Reorder columns\n",
    "\n",
    "reads_tax_df %>%\n",
    "    head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Write samples file\n",
    "mifaser_samplesfile = file.path(sheets_dir, \"samples_file_mifaser.tsv\")\n",
    "write_tsv(reads_tax_df,\n",
    "    file = mifaser_samplesfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create slurm script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mifaser_slurm_raw = str_glue(.open = \"[\", .close = \"]\",\n",
    "\"#!/bin/bash\n",
    "##############################\n",
    "#       Parameters           #\n",
    "##############################\n",
    "\n",
    "# This section will tell the cluster what are the resources your job will need.\n",
    "# Change the parameters accordingly and carefully!\n",
    "# The parameters here are a sensible start.\n",
    "\n",
    "# Name of the job\n",
    "#SBATCH --job-name=[[job_name]]\n",
    "\n",
    "# Generate an output file and give it a name\n",
    "#SBATCH --output=%x-%j.out\n",
    "\n",
    "# Number of tasks\n",
    "#SBATCH --ntasks=1\n",
    "\n",
    "# Number of cpus that this task will need\n",
    "#SBATCH --cpus-per-task=16\n",
    "\n",
    "# Specify the total memory required per node\n",
    "#SBATCH --mem=64G\n",
    "\n",
    "# Specify the maximum time this job can take to run before being killed (hh:mm:ss)\n",
    "#SBATCH --time=23:59:59\n",
    "\n",
    "# Specify number of array jobs\n",
    "#SBATCH --array=[[array_jobs]]\n",
    "\n",
    "# job information\n",
    "scontrol show job ${SLURM_JOB_ID}\n",
    "\n",
    "# per node\n",
    "# prep\n",
    "CONDA_PATH='[[conda_install]'\n",
    "echo ${CONDA_PATH}\n",
    "source ${CONDA_PATH}/etc/profile.d/conda.sh\n",
    "\n",
    "# Specify the path to the config file\n",
    "config=[[samples_file]]\n",
    "\n",
    "# Extract the sample name for the current $SLURM_ARRAY_TASK_ID\n",
    "sample=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $2}' $config)\n",
    "\n",
    "# Extract the path to the forward read for the current $SLURM_ARRAY_TASK_ID\n",
    "forward=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $3}' $config)\n",
    "\n",
    "# Extract the path to the reverse read for the current $SLURM_ARRAY_TASK_ID\n",
    "reverse=$(awk -v ArrayTaskID=$SLURM_ARRAY_TASK_ID '$1==ArrayTaskID {print $4}' $config)\n",
    "\n",
    "# Print to a file a message that includes the current $SLURM_ARRAY_TASK_ID and sample name\n",
    "echo This is array task ${SLURM_ARRAY_TASK_ID}, the sample name is ${sample} the forward read is ${forward} and the reverse is ${reverse}\n",
    "\n",
    "# do your real computation\n",
    "conda activate [[conda_env]]\n",
    "cd [[mifaser_repo]]\n",
    "python -m mifaser --lanes ${forward} ${reverse} -o [[out_dir]]/${sample}_out -d GS-21-all -c 16\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "mifaser_slurm = str_glue(mifaser_slurm_raw,\n",
    "        job_name = \"mifaser_run\", \n",
    "        array_jobs = str_c(\"1-\", nrow(reads_tax_df)), # number of array jobs should be expressed as 1-<number of samples to run>, if 10 samples, 1-10\n",
    "        conda_install = \"/mnt/lustre/groups/maier/maide581/bin/miniconda3\", # Path to your conda installation\n",
    "        samples_file = mifaser_samplesfile, # Samples file we created above\n",
    "        mifaser_repo = mifaser_dir, # Path to the mifaser git repo\n",
    "        out_dir = out_dir,\n",
    "        conda_env = conda_env, .open = \"[\", .close = \"]\") # Name of conda environment ro tun mifaser, defined above\n",
    "\n",
    "mifaser_slurm %>%\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Write file\n",
    "mifaser_slurmfile = file.path(base_dir, \"bin/mifaser_slurm.sh\")\n",
    "write_lines(mifaser_slurm, mifaser_slurmfile)\n",
    "mifaser_slurmfile"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
